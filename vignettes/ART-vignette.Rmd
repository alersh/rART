---
title: "Introduction to rART: A R package for Implementing Adaptive Resonance Theory"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to rART: A R package for Implementing Adaptive Resonance Theory}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(rART)
library(mlbench)
```

## ART is now available in R!

rART is a package containing the implementations of various ART (Adaptive Resonance Theory) models. ART is a class of neural network model that can perform both unsupervised and supervised (called ARTMAP) clustering online. The package is mainly written in Rcpp.

## What is Adaptive Resonance Theory?

Adaptive Resonance Theory (ART) is a neural network model developed by Stephen Grossberg. It is a neuro-cognitive model that attempts to explain how the brain learns and interacts with the stimuli in the environment. The main ART model consists of a winner-take-all system, with the ability to dynamically generate additional categories for capturing different patterns in the data. These two properties help solve the stability-plasticity problem that plagues most machine learning algorithms: how to learn new patterns without erasing the learned memories.

ART also shows several advantages over other machine learning models. These include:

1. online learning, 
2. fast learning,
3. explanable.

For a comprehensive review of ART and its variants, please read da Silva et al., 2019 ^1^.

## The rART package

The rART package currently provides the implementation of two types of ART architecture: the standard ART and topological ART (TopoART). TopoART forms linkages between clusters to enable the learning of the topology from the data. Additionally, TopoART possesses a noise filtering mechanism that prevents overfitting.

Currently, rART provides the fuzzy and hypersphere learning rules for both the standard and the topological versions. The first generations of ART (i.e. ART 1 and ART 2) are not included in this package as they are not used for most practical purposes. In the future, other learning rules and architecture will be added.

## Installation

rART is not available on CRAN yet, but you can install the latest development version:

remotes::install_github("alersh/rART")

## Usage

### ART

ART is an unsupervised learning model and its object can be instantiated using the function ART(). Two learning rules are available: fuzzy and hypersphere. If the fuzzy rule is chosen, then all data must be normalized between 0 and 1. Additionally, the complement of each data point d, which is 1 - d, must be created. Thus, if the dataset has a dimension of n, then the dimension of the actual input to the Fuzzy ART network is n x 2. Users are required to normalize the data prior to training and testing the data. Complement coding is taken care of by rART internally.

The Fuzzy ART network has two hyperparameters: Learning rate ($\beta$) and vigilance ($\rho$). The learning rate $\beta$ must be between 0 and 1. Fast learning ($\beta$ = 1) can be achieved and is normally set as the default. The vigilance parameter $\rho$ decides whether an input pattern closely matches with the weight pattern of the selected category. The value must be between 0 and 1. A smaller value provides more generalization. 

Here is an example of using Fuzzy ART to cluster different shapes:

```{r, fig.width = 7, fig.height = 4}
trainShapes <- mlbench.shapes(n = 5000)
trainShapes$x <- normalize(trainShapes$x)
art <- ART(rule = "fuzzy", dimension = 2, vigilance = 0.93) # create an ART object
train(art, as.matrix(trainShapes$x)) 
plot(art, id = 0, .data = trainShapes$x) # plot the data and the weights.
```

### ARTMAP
ARTMAP is the supervised learning model. rART provides both the standard and simplified versions of ARTMAP. For the descriptions on the standard and simplified ARTMAP, please see da Silva et al^1^. For most classification problems, users should choose the simplified method as it is faster and uses less memory. The standard method is used for regression problems.

Here is a circle-in-a-square classification problem solved with the simplified Fuzzy ARTMAP:

```{r, fig.width = 7, fig.height = 4}
# circle in a square
trainCirSquare <- mlbench.circle(n = 10000)
testCirSquare <- mlbench.circle(n = 1000)
artmap <- ARTMAP(rule = "fuzzy", dimension = 2, vigilance = 0.8)
train(artmap, trainCirSquare$x, trainCirSquare$classes)
plot(artmap, .data = trainCirSquare$x, classes = trainCirSquare$classes) # create the 2 dimensional plot of the data and the weights
p <- predict(artmap, .data = testCirSquare$x, classLabels = testCirSquare$classes)
sum(p$matched)/length(p$matched) * 100 # percent correct
```

The user can also implement the standard fuzzy ARTMAP. In this case, the user must first convert the class labels into dummy (binary) codes. rART provides two functions to aid the conversion. The createDummyCodeMap() takes the unique target labels and convert them to dummy codes. The function encodeLabel() converts all the target labels into dummy codes using this dummy code map. 

```{r, fig.width = 7, fig.height = 4}
# circle in a square
trainCirSquare <- mlbench.circle(n = 10000)
testCirSquare <- mlbench.circle(n = 1000)
artmap <- ARTMAP(rule = "fuzzy", dimension = 2, vigilance = 0.9, simplified = FALSE)
dummyMap <- createDummyCodeMap(unique(trainCirSquare$classes))
trainCirSquare$dummyClasses <- encodeLabel(trainCirSquare$classes, dummyMap)
testCirSquare$dummyClasses <- encodeLabel(testCirSquare$classes, dummyMap)
train(artmap, trainCirSquare$x, dummyClasses = trainCirSquare$dummyClasses)
plot(artmap, .data = trainCirSquare$x, classes = trainCirSquare$dummyClasses, dummyCodeMap = dummyMap) # create the 2 dimensional plot of the data and the weights
p <- predict(artmap, .data = testCirSquare$x, dummyClasses = testCirSquare$dummyClasses)
sum(p$matched, na.rm = T)/length(p$matched) * 100 # percent correct
```

### Fuzzy TopoART

TopoART stands for "Topological ART". It can learn the topology from the data by linking clusters together. A TopoART network consists of two ART modules in series. Within each module, every learned category possesses a counter that counts the number of samples encoded by that category. A hyperparameter $\phi$ determines the minimum number of sample required for a category to become permanent. Every $\tau$ learning cycle, those categories containing samples fewer than $\phi$ will be removed. In the first module, those samples that belong to the permanent categories will be retained and advanced to the second module where they will be further classified into finer categories. Thus, the second module learns a subset of the data that are filtered by the first module. 

The learning of the topology can be done in both TopoART modules. During learning, once the best matching category is found, the second best matching category will be searched. If this second best mathcing category is found, then a link is created between this category and the best matching category. The learning rate for the second best matching category will be smaller than that for the best matching category.

Here is an example of using TopoART to cluster a smiley face. Notice the smaller category size in module 2 when compare to the size in module 1. Also, notice that some of the points in module 2 are not enclosed by any cluster. The user can specify which module to plot by entering the id number (0 for the first module and 1 for the second module).

```{r, fig.width = 7, fig.height = 4}
# smiley face
trainSmiley <- mlbench.smiley(n = 2000)
testSmiley <- mlbench.smiley(n = 1000)
z <- normalize(trainSmiley$x)
set.seed(123)
x <- runif(1000)
y <- runif(1000)
z <- rbind(z, cbind(x,y))
z <- z[sample.int(nrow(z)), ]
topoart <- TopoART(rule = "fuzzy", dimension = 2, vigilance = 0.88, tau = 200, phi = 5)
train(topoart, z)
plot(topoart, id = 0, z) # the ART a module
plot(topoart, id = 1, z) # the ART b module
```

## Hypersphere ARTs

In all of the above examples, the user can substitute the fuzzy rule with the hypersphere rule. The advantages of using the hypersphere rule are: 1) it does not require complement coding, and 2) it does not require normalization.

## Final Words

I hope you will find this package useful. If you discover any problem, please contact me at alersh@gmail.com and provide me with the details of the problem. 



1. da Silva, L.E.B, Elnabarawy, I., and Wunsch II, D.C. A Survey of Adaptive Resonance Theory Neural Network Models for Engineering Applications. Neural Networks, vol 120, Dec 2019. pp 167 - 203.]
